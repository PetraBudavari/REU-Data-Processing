{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open annotation data for start and end unix times of task videos\n",
    "# read motion data from video_ID\n",
    "# parse motion data txt file such that each measurement is in separate column and each sensor is in separate row\n",
    "# (one sensor at a time)\n",
    "# create timestamp for each frame in video \n",
    "# merge frame and motion timestamps, sort time and make index\n",
    "# then interpolate sensor measurements\n",
    "# merge sensors for each video\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pd.set_option(\"display.precision\", 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filepath, sensor_id, max_lines=None, header_startswith='Format for each'):\n",
    "    '''Parse a kinematics file'''\n",
    "\n",
    "    with open(filepath,'r') as f:\n",
    "\n",
    "        # read header info\n",
    "        header = f.readline()\n",
    "        if header_startswith:\n",
    "            # check for header where the columns names are for the sensors\n",
    "            if not header.startswith(header_startswith): \n",
    "                return None\n",
    "            \n",
    "        # loop over the lines of sensor data\n",
    "        for line_number, line in enumerate(f.readlines()):\n",
    "            if max_lines is None or (max_lines > 0 and line_number < max_lines):\n",
    "                sensor = line.split('Sensor')\n",
    "                # pick the correct sensor\n",
    "                s = sensor[sensor_id]\n",
    "                # split the data and exclude first item with the sensor id\n",
    "                t = s.split()[1:]\n",
    "                # this generator yields every item one by one\n",
    "                yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Kinematic_data/891044.txt'),\n",
       " WindowsPath('D:/Kinematic_data/891043.txt'),\n",
       " WindowsPath('D:/Kinematic_data/891039.txt'),\n",
       " WindowsPath('D:/Kinematic_data/891038.txt')]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location of data \n",
    "root = Path('D:\\\\')\n",
    "dir = root / 'Kinematic_data' \n",
    "\n",
    "csv = 'C:/Users/petra/REU/unix_videos.csv'\n",
    "dfv = pd.read_csv(csv)\n",
    "\n",
    "# find all kinematics files in the folder\n",
    "file_list = list(dir.glob('*.txt'))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891038.txt\n",
      "D:\\Kinematic_data\\891038.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop over videos\n",
    "for index, row in dfv.iterrows():\n",
    "    file = int(row[\"video_id\"])\n",
    "    fname = f'{file}.txt'\n",
    "    print (fname)\n",
    "\n",
    "    filename = dir / fname\n",
    "    print(filename)\n",
    "    filepath = Path(filename)\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        \n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(dir):\n",
    "        for i in range(1,8):\n",
    "\n",
    "            colnames = ['status', 'x', 'y', 'z', 'azimuth', 'elevation', 'roll', 'button', 'quality', 'time']\n",
    "\n",
    "            \n",
    "            sensor_id = i\n",
    "\n",
    "            max_lines = 100000  # for testing\n",
    "\n",
    "            df = pd.DataFrame(columns=colnames)\n",
    "\n",
    "            # load dataframe row by row\n",
    "            for row in parse(filepath, sensor_id, max_lines):\n",
    "                df.loc[len(df)] = row\n",
    "\n",
    "            # convert columns one by one\n",
    "            coltypes = dict(\n",
    "                x=np.float32, y=np.float32, z=np.float32, \n",
    "                azimuth=np.float32, elevation=np.float32, roll=np.float32, \n",
    "                button=np.int8, quality=np.int8\n",
    "                )\n",
    "\n",
    "            for c,t in coltypes.items():\n",
    "                df[c] = df[c].astype(t)\n",
    "\n",
    "            df['t'] = df.time.astype(np.float64)\n",
    "            df['Sensor'] = sensor_id * np.ones_like(df.index)\n",
    "\n",
    "            #df['video_time'] = df.t - df.t[0]\n",
    "\n",
    "            #print (df.time[0], df.t[0])\n",
    "            print(df.dtypes)\n",
    "            df\n",
    "            #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "ending violation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[465], line 82\u001b[0m\n\u001b[0;32m     76\u001b[0m             output\u001b[39m.\u001b[39munlink() \n\u001b[0;32m     77\u001b[0m         merged_df\u001b[39m.\u001b[39mto_csv(output, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m interpolation()\n",
      "Cell \u001b[1;32mIn[465], line 42\u001b[0m, in \u001b[0;36minterpolation\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m# test time intervals\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39massert\u001b[39;00m times\u001b[39m.\u001b[39mt\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m df\u001b[39m.\u001b[39mt\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mstarting violation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 42\u001b[0m \u001b[39massert\u001b[39;00m times\u001b[39m.\u001b[39mt\u001b[39m.\u001b[39mvalues[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m df\u001b[39m.\u001b[39mt\u001b[39m.\u001b[39mvalues[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mending violation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[39m#join the motion data and the frame times data frames \u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m#merged_df = pd.merge(times, df[['t', 'x']], left_on='time', right_on='t', how='outer')\u001b[39;00m\n\u001b[0;32m     47\u001b[0m merged_df \u001b[39m=\u001b[39m times\u001b[39m.\u001b[39mmerge(df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m'\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: ending violation"
     ]
    }
   ],
   "source": [
    "def interpolation(args = None):\n",
    "    #parser = argparse.ArgumentParser(\n",
    "        #description='Interolation of motion data on video frames')\n",
    "\n",
    "    #parser.add_argument('csv_unix', help='File of Start and End UNIX timestamps for processed videos')       \n",
    "    #parser.add_argument('-f', '--fps', default=30, help=\"Frame rate\")\n",
    "\n",
    "    #args = parser.parse_args()\n",
    "    #csv = args.csv_unix\n",
    "\n",
    "    csv = 'C:/Users/petra/REU/unix_videos.csv'\n",
    "    dfv = pd.read_csv(csv)\n",
    "\n",
    "    # convenience class like a dict\n",
    "    if args is None:\n",
    "        args = Bunch()\n",
    "        args.fps = 30\n",
    "        args.frames = 50\n",
    "\n",
    "    # loop over videos - iterate through the unix start and end times for tasks\n",
    "    for index, row in dfv.iterrows():\n",
    "        # useful time interval\n",
    "        start_timestamp = row['unix_start_time']\n",
    "        end_timestamp = row['unix_end_time']\n",
    "        \n",
    "        # total number of frames\n",
    "      \n",
    "        frames = int(np.floor((end_timestamp - start_timestamp) * args.fps))\n",
    "        #frames = 3 \n",
    "        display(frames)\n",
    "        # new dataframe for the time of each frame\n",
    "        f = np.arange(frames) # array of frame numbers 0,1,2...,frames-1\n",
    "        t = start_timestamp + f / args.fps\n",
    "        times = pd.DataFrame({'t': t, 'frame': f})\n",
    "\n",
    "        if False:\n",
    "            display(times)\n",
    "            display(df[['t', 'x']])\n",
    "\n",
    "        # test time intervals\n",
    "        assert times.t.values[0] > df.t.values[0], 'starting violation'\n",
    "        assert times.t.values[-1] < df.t.values[-1], 'ending violation'\n",
    "\n",
    "        #join the motion data and the frame times data frames \n",
    "        #merged_df = pd.merge(times, df[['t', 'x']], left_on='time', right_on='t', how='outer')\n",
    "\n",
    "        merged_df = times.merge(df, how='outer', on='t')\n",
    "        display(merged_df[['t','x','y']])\n",
    "\n",
    "        # sort the unix times column in numerical order \n",
    "        merged_df = merged_df.sort_values('t')\n",
    "        merged_df.set_index('t', inplace=True)\n",
    "\n",
    "        # sensor columns to interpolate are all but a few\n",
    "        sensor_cols = list(df.columns) # everything kinematic file\n",
    "        for c in ['t', 'status', 'time', 'Sensor']: # excluding these columns\n",
    "            sensor_cols.remove(c)\n",
    "        print (sensor_cols)\n",
    "\n",
    "        # interpolate selected columns in place \n",
    "        for c in sensor_cols:\n",
    "            merged_df[c].interpolate(inplace=True, method='linear')\n",
    "        \n",
    "        display(merged_df)\n",
    "\n",
    "        # exclude rows without frame numbers, i.e., NaN \n",
    "        merged_df = merged_df[merged_df.frame.apply(lambda f: f >= 0)]\n",
    "\n",
    "        display(merged_df)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        video = int(row['video_id'])\n",
    "        output = Path(f'''{video}_Sensor{sensor_id}.csv''')\n",
    "        # delete output csv if already exists\n",
    "        if output.exists():\n",
    "            output.unlink() \n",
    "        merged_df.to_csv(output, index=False)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "interpolation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
